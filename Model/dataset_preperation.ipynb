{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "893ca563",
   "metadata": {},
   "source": [
    "# Skin Disease Detection using Mobile Application\n",
    "## Final Year Project 2\n",
    "Ahmad Daniel Ikhwan Bin Rosli <br>\n",
    "1201103071"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e045657",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNet, MobileNetV2, MobileNetV3Large\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bd9ed03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/shubhamgoel27/dermnet\n",
      "License(s): Attribution-NonCommercial-NoDerivatives 4.0 International (CC BY-NC-ND 4.0)\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d shubhamgoel27/dermnet --unzip -p datasets/dermnet_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9024c7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_classes = {\n",
    "    \"Acne and Rosacea Photos\": \"Acne\",\n",
    "    \"Eczema Photos\": \"Eczema\",\n",
    "    \"Psoriasis pictures Lichen Planus and related diseases\": \"Psoriasis\",\n",
    "    \"Tinea Ringworm Candidiasis and other Fungal Infections\": \"Tinea\",\n",
    "    \"Melanoma Skin Cancer Nevi and Moles\": \"Melanoma\"\n",
    "}\n",
    "\n",
    "raw_path = Path(\"datasets/dermnet_raw\")     \n",
    "prep_path = Path(\"datasets/dermnet_prep\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89330663",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying Acne (train): 100%|██████████| 840/840 [00:08<00:00, 104.16it/s]\n",
      "Copying Acne (test): 100%|██████████| 308/308 [00:02<00:00, 131.26it/s]\n",
      "Copying Eczema (train): 100%|██████████| 1235/1235 [00:11<00:00, 103.21it/s]\n",
      "Copying Eczema (test): 100%|██████████| 309/309 [00:02<00:00, 105.07it/s]\n",
      "Copying Psoriasis (train): 100%|██████████| 1405/1405 [00:13<00:00, 103.14it/s]\n",
      "Copying Psoriasis (test): 100%|██████████| 352/352 [00:03<00:00, 103.64it/s]\n",
      "Copying Tinea (train): 100%|██████████| 1300/1300 [00:12<00:00, 105.06it/s]\n",
      "Copying Tinea (test): 100%|██████████| 325/325 [00:03<00:00, 106.83it/s]\n",
      "Copying Melanoma (train): 100%|██████████| 463/463 [00:04<00:00, 100.85it/s]\n",
      "Copying Melanoma (test): 100%|██████████| 116/116 [00:01<00:00, 103.52it/s]\n"
     ]
    }
   ],
   "source": [
    "if prep_path.exists():\n",
    "    shutil.rmtree(prep_path)\n",
    "prep_path.mkdir(parents=True)\n",
    "\n",
    "for original_name, clean_name in target_classes.items():\n",
    "    dst_dir = prep_path / clean_name\n",
    "    dst_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    img_counter = 0\n",
    "\n",
    "    for split in ['train', 'test']:\n",
    "        src_dir = raw_path / split / original_name\n",
    "        if not src_dir.exists():\n",
    "            continue\n",
    "\n",
    "        for img_file in tqdm(list(src_dir.glob(\"*.jpg\")), desc=f\"Copying {clean_name} ({split})\"):\n",
    "            dst_file = dst_dir / f\"{clean_name}_{img_counter:05d}.jpg\"\n",
    "            shutil.copy(img_file, dst_file)\n",
    "            img_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50c69e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    filepath label\n",
      "0  datasets\\dermnet_prep\\Acne\\Acne_00000.jpg  Acne\n",
      "1  datasets\\dermnet_prep\\Acne\\Acne_00001.jpg  Acne\n",
      "2  datasets\\dermnet_prep\\Acne\\Acne_00002.jpg  Acne\n",
      "3  datasets\\dermnet_prep\\Acne\\Acne_00003.jpg  Acne\n",
      "4  datasets\\dermnet_prep\\Acne\\Acne_00004.jpg  Acne\n",
      "label\n",
      "Psoriasis    1757\n",
      "Tinea        1625\n",
      "Eczema       1544\n",
      "Acne         1148\n",
      "Melanoma      579\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "filepaths = []\n",
    "labels = []\n",
    "\n",
    "for class_folder in prep_path.iterdir():\n",
    "    if class_folder.is_dir():\n",
    "        for img_file in class_folder.glob(\"*.jpg\"):\n",
    "            filepaths.append(str(img_file))\n",
    "            labels.append(class_folder.name)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'filepath': filepaths,\n",
    "    'label': labels\n",
    "})\n",
    "\n",
    "print(df.head())\n",
    "print(df['label'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "052708bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (5322, 2)\n",
      "Val: (665, 2)\n",
      "Test: (666, 2)\n"
     ]
    }
   ],
   "source": [
    "train_df, temp_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "\n",
    "val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['label'], random_state=42)\n",
    "\n",
    "print(\"Train:\", train_df.shape)\n",
    "print(\"Val:\", val_df.shape)\n",
    "print(\"Test:\", test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "616a92ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    brightness_range=[0.8, 1.2],\n",
    "    shear_range=0.15,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ce2860e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5322 validated image filenames belonging to 5 classes.\n",
      "Found 665 validated image filenames belonging to 5 classes.\n",
      "Found 666 validated image filenames belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "# create data generators \n",
    "train_gen = train_datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_gen = val_test_datagen.flow_from_dataframe(\n",
    "    dataframe=val_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_gen = val_test_datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30a66d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training MobileNet (50 epochs)...\n",
      "Epoch 1/50\n",
      "167/167 [==============================] - 114s 655ms/step - loss: 1.4593 - accuracy: 0.3700 - val_loss: 1.2882 - val_accuracy: 0.4481\n",
      "Epoch 2/50\n",
      "167/167 [==============================] - 59s 354ms/step - loss: 1.2174 - accuracy: 0.5002 - val_loss: 1.2024 - val_accuracy: 0.4857\n",
      "Epoch 3/50\n",
      "167/167 [==============================] - 60s 356ms/step - loss: 1.1425 - accuracy: 0.5365 - val_loss: 1.1536 - val_accuracy: 0.5263\n",
      "Epoch 4/50\n",
      "167/167 [==============================] - 65s 386ms/step - loss: 1.0896 - accuracy: 0.5622 - val_loss: 1.1374 - val_accuracy: 0.5323\n",
      "Epoch 5/50\n",
      "167/167 [==============================] - 64s 383ms/step - loss: 1.0399 - accuracy: 0.5889 - val_loss: 1.1041 - val_accuracy: 0.5474\n",
      "Epoch 6/50\n",
      "167/167 [==============================] - 63s 375ms/step - loss: 1.0201 - accuracy: 0.5988 - val_loss: 1.0816 - val_accuracy: 0.5564\n",
      "Epoch 7/50\n",
      "167/167 [==============================] - 62s 372ms/step - loss: 0.9889 - accuracy: 0.6090 - val_loss: 1.0686 - val_accuracy: 0.5519\n",
      "Epoch 8/50\n",
      "167/167 [==============================] - 62s 368ms/step - loss: 0.9619 - accuracy: 0.6214 - val_loss: 1.0562 - val_accuracy: 0.5835\n",
      "Epoch 9/50\n",
      "167/167 [==============================] - 62s 369ms/step - loss: 0.9436 - accuracy: 0.6336 - val_loss: 1.0490 - val_accuracy: 0.5744\n",
      "Epoch 10/50\n",
      "167/167 [==============================] - 61s 365ms/step - loss: 0.9123 - accuracy: 0.6473 - val_loss: 1.0341 - val_accuracy: 0.5850\n",
      "Epoch 11/50\n",
      "167/167 [==============================] - 61s 367ms/step - loss: 0.8935 - accuracy: 0.6556 - val_loss: 1.0176 - val_accuracy: 0.5850\n",
      "Epoch 12/50\n",
      "167/167 [==============================] - 61s 366ms/step - loss: 0.8741 - accuracy: 0.6608 - val_loss: 1.0075 - val_accuracy: 0.6015\n",
      "Epoch 13/50\n",
      "167/167 [==============================] - 63s 375ms/step - loss: 0.8552 - accuracy: 0.6757 - val_loss: 0.9958 - val_accuracy: 0.5910\n",
      "Epoch 14/50\n",
      "167/167 [==============================] - 65s 387ms/step - loss: 0.8369 - accuracy: 0.6759 - val_loss: 0.9854 - val_accuracy: 0.6030\n",
      "Epoch 15/50\n",
      "167/167 [==============================] - 63s 377ms/step - loss: 0.8328 - accuracy: 0.6830 - val_loss: 0.9840 - val_accuracy: 0.6015\n",
      "Epoch 16/50\n",
      "167/167 [==============================] - 63s 375ms/step - loss: 0.8178 - accuracy: 0.6913 - val_loss: 0.9784 - val_accuracy: 0.6165\n",
      "Epoch 17/50\n",
      "167/167 [==============================] - 64s 381ms/step - loss: 0.7941 - accuracy: 0.6965 - val_loss: 0.9765 - val_accuracy: 0.6120\n",
      "Epoch 18/50\n",
      "167/167 [==============================] - 63s 374ms/step - loss: 0.7724 - accuracy: 0.7033 - val_loss: 0.9561 - val_accuracy: 0.6195\n",
      "Epoch 19/50\n",
      "167/167 [==============================] - 63s 377ms/step - loss: 0.7656 - accuracy: 0.7133 - val_loss: 0.9644 - val_accuracy: 0.6331\n",
      "Epoch 20/50\n",
      "167/167 [==============================] - 61s 365ms/step - loss: 0.7565 - accuracy: 0.7118 - val_loss: 0.9462 - val_accuracy: 0.6241\n",
      "Epoch 21/50\n",
      "167/167 [==============================] - 60s 357ms/step - loss: 0.7459 - accuracy: 0.7172 - val_loss: 0.9299 - val_accuracy: 0.6301\n",
      "Epoch 22/50\n",
      "167/167 [==============================] - 60s 356ms/step - loss: 0.7381 - accuracy: 0.7213 - val_loss: 0.9282 - val_accuracy: 0.6376\n",
      "Epoch 23/50\n",
      "167/167 [==============================] - 60s 359ms/step - loss: 0.7262 - accuracy: 0.7253 - val_loss: 0.9399 - val_accuracy: 0.6346\n",
      "Epoch 24/50\n",
      "167/167 [==============================] - 60s 359ms/step - loss: 0.7138 - accuracy: 0.7356 - val_loss: 0.9216 - val_accuracy: 0.6526\n",
      "Epoch 25/50\n",
      "167/167 [==============================] - 61s 364ms/step - loss: 0.7124 - accuracy: 0.7274 - val_loss: 0.9125 - val_accuracy: 0.6571\n",
      "Epoch 26/50\n",
      "167/167 [==============================] - 61s 367ms/step - loss: 0.6948 - accuracy: 0.7424 - val_loss: 0.9222 - val_accuracy: 0.6361\n",
      "Epoch 27/50\n",
      "167/167 [==============================] - 61s 364ms/step - loss: 0.6971 - accuracy: 0.7377 - val_loss: 0.9114 - val_accuracy: 0.6511\n",
      "Epoch 28/50\n",
      "167/167 [==============================] - 63s 376ms/step - loss: 0.6807 - accuracy: 0.7480 - val_loss: 0.9106 - val_accuracy: 0.6496\n",
      "Epoch 29/50\n",
      "167/167 [==============================] - 62s 367ms/step - loss: 0.6601 - accuracy: 0.7563 - val_loss: 0.9169 - val_accuracy: 0.6526\n",
      "Epoch 30/50\n",
      "167/167 [==============================] - 61s 363ms/step - loss: 0.6562 - accuracy: 0.7569 - val_loss: 0.9071 - val_accuracy: 0.6541\n",
      "Epoch 31/50\n",
      "167/167 [==============================] - 62s 371ms/step - loss: 0.6484 - accuracy: 0.7574 - val_loss: 0.9049 - val_accuracy: 0.6481\n",
      "Epoch 32/50\n",
      "167/167 [==============================] - 62s 369ms/step - loss: 0.6345 - accuracy: 0.7629 - val_loss: 0.9211 - val_accuracy: 0.6586\n",
      "Epoch 33/50\n",
      "167/167 [==============================] - 61s 367ms/step - loss: 0.6274 - accuracy: 0.7702 - val_loss: 0.9031 - val_accuracy: 0.6556\n",
      "Epoch 34/50\n",
      "167/167 [==============================] - 60s 361ms/step - loss: 0.6190 - accuracy: 0.7745 - val_loss: 0.8988 - val_accuracy: 0.6692\n",
      "Epoch 35/50\n",
      "167/167 [==============================] - 60s 361ms/step - loss: 0.6167 - accuracy: 0.7725 - val_loss: 0.8858 - val_accuracy: 0.6677\n",
      "Epoch 36/50\n",
      "167/167 [==============================] - 60s 357ms/step - loss: 0.6151 - accuracy: 0.7704 - val_loss: 0.8906 - val_accuracy: 0.6632\n",
      "Epoch 37/50\n",
      "167/167 [==============================] - 60s 357ms/step - loss: 0.6053 - accuracy: 0.7740 - val_loss: 0.8951 - val_accuracy: 0.6541\n",
      "Epoch 38/50\n",
      "167/167 [==============================] - 60s 355ms/step - loss: 0.5921 - accuracy: 0.7792 - val_loss: 0.8926 - val_accuracy: 0.6556\n",
      "Epoch 39/50\n",
      "167/167 [==============================] - 60s 358ms/step - loss: 0.5902 - accuracy: 0.7869 - val_loss: 0.8900 - val_accuracy: 0.6677\n",
      "Epoch 40/50\n",
      "167/167 [==============================] - 60s 357ms/step - loss: 0.5787 - accuracy: 0.7882 - val_loss: 0.8923 - val_accuracy: 0.6526\n",
      "Epoch 41/50\n",
      "167/167 [==============================] - 60s 359ms/step - loss: 0.5684 - accuracy: 0.7882 - val_loss: 0.8753 - val_accuracy: 0.6737\n",
      "Epoch 42/50\n",
      "167/167 [==============================] - 59s 354ms/step - loss: 0.5691 - accuracy: 0.7901 - val_loss: 0.8837 - val_accuracy: 0.6511\n",
      "Epoch 43/50\n",
      "167/167 [==============================] - 60s 358ms/step - loss: 0.5521 - accuracy: 0.8016 - val_loss: 0.8712 - val_accuracy: 0.6707\n",
      "Epoch 44/50\n",
      "167/167 [==============================] - 60s 357ms/step - loss: 0.5576 - accuracy: 0.7982 - val_loss: 0.8716 - val_accuracy: 0.6707\n",
      "Epoch 45/50\n",
      "167/167 [==============================] - 60s 357ms/step - loss: 0.5464 - accuracy: 0.8001 - val_loss: 0.8736 - val_accuracy: 0.6617\n",
      "Epoch 46/50\n",
      "167/167 [==============================] - 60s 358ms/step - loss: 0.5417 - accuracy: 0.8123 - val_loss: 0.8655 - val_accuracy: 0.6812\n",
      "Epoch 47/50\n",
      "167/167 [==============================] - 60s 355ms/step - loss: 0.5364 - accuracy: 0.8046 - val_loss: 0.8595 - val_accuracy: 0.6872\n",
      "Epoch 48/50\n",
      "167/167 [==============================] - 61s 367ms/step - loss: 0.5297 - accuracy: 0.8140 - val_loss: 0.8648 - val_accuracy: 0.6797\n",
      "Epoch 49/50\n",
      "167/167 [==============================] - 60s 358ms/step - loss: 0.5232 - accuracy: 0.8147 - val_loss: 0.8559 - val_accuracy: 0.6797\n",
      "Epoch 50/50\n",
      "167/167 [==============================] - 60s 361ms/step - loss: 0.5147 - accuracy: 0.8121 - val_loss: 0.8698 - val_accuracy: 0.6722\n"
     ]
    }
   ],
   "source": [
    "# mobilenet\n",
    "print(\"Training MobileNet (50 epochs)...\")\n",
    "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "num_classes = len(train_gen.class_indices)\n",
    "preds = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=preds)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "early_stop = EarlyStopping(patience=20, restore_best_weights=True, verbose=1)\n",
    "\n",
    "history_mobilenet = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "model.save(\"mobilenet_model.h5\")\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6936a717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mobilenetv2\n",
    "print(\"Training MobileNetV2 (50 epochs)...\")\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(train_gen.num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=preds)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(patience=20, restore_best_weights=True, verbose=1)\n",
    "\n",
    "history_mobilenetv2 = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "model.save(\"mobilenetv2_model.h5\")\n",
    "K.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854fbd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mobilenetv3\n",
    "print(\"Training MobileNetV3Small (50 epochs)...\")\n",
    "base_model = MobileNetV3Large(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = GlobalAveragePooling2D()(base_model.output)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "preds = Dense(train_gen.num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=preds)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(patience=20, restore_best_weights=True, verbose=1)\n",
    "\n",
    "history_mobilenetv3 = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stop]\n",
    ")\n",
    "\n",
    "model.save(\"mobilenetv3Large_model.h5\")\n",
    "K.clear_session()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fyp-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
